from nltk.tokenize import word_tokenize

data = word_tokenize('Hello Ranjith is one big asshole (kakkas). I am wondering '
                     'how you will tokenize such words. Be happy in life')

print(data)
